# This yaml file is meant to be used by the script:
# tests/test_mlp_nested.py

!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: 'train',
        one_hot: 1,
        start: 0,
        stop: %(train_stop)i
    },
    model: !obj:pylearn2.models.mlp.MLP {
        layers: [!obj:pylearn2.models.mlp.MLP {
        layer_name: 'mlp1', 
        layers: [
        !obj:pylearn2.models.mlp.MLP {
        layer_name: 'mlp3', 
        layers: [ !obj:pylearn2.models.mlp.Tanh {
                     layer_name: 'h0',
                     dim: %(dim_h0)i,
                     sparse_init: 15
                 },  !obj:pylearn2.models.mlp.RectifiedLinear {
                     layer_name: 'h1',
                     dim: %(dim_h1)i,
                     sparse_init: %(sparse_init_h1)i
                 }
                ]
        },
        !obj:pylearn2.models.mlp.MLP {
        layer_name: 'mlp2', 
        layers: [ !obj:pylearn2.models.mlp.Tanh {
                     layer_name: 'h0',
                     dim: %(dim_h2)i,
                     sparse_init: 15
                 },  !obj:pylearn2.models.mlp.RectifiedLinear {
                     layer_name: 'h1',
                     dim: %(dim_h3)i,
                     sparse_init: %(sparse_init_h1)i
                 }, !obj:pylearn2.models.mlp.Softmax {
                     layer_name: 'y',
                     n_classes: 10,
                     irange: 0.
                 }
                ],
        }], 
        }],
        nvis: 784, 
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 100,
        learning_rate: .01,
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'train',
                              one_hot: 1,
                              start: 50000,
                              stop: %(valid_stop)i
                          },
                'test'  : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'test',
                              one_hot: 1,
                          }
            },
        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [
            !obj:pylearn2.costs.mlp.Default {
            }, 
            !obj:pylearn2.costs.mlp.L1WeightDecay {
                coeffs: [ [ [ .0005, .0005 ], [ .00005, .00005, .00005 ] ] ]
            },
            !obj:pylearn2.costs.mlp.WeightDecay {
                coeffs: [ [ [ .0005, .0005 ], [ .00005, .00005, .00005 ] ] ]
            }
            ]
        },
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
            init_momentum: .5
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_mlp1_mlp2_y_misclass",
                    prop_decrease: 0.,
                    N: 10
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: %(max_epochs)i
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_mlp1_mlp2_y_misclass',
             save_path: "mlp_3_best.pkl"
        }, !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            start: 1,
            saturate: 10,
            final_momentum: .99
        }
    ]
}
